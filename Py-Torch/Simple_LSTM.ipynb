{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ohE-qOrp1AmG"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "`nn.LSTM` is a class within the PyTorch framework, specifically part of the torch.nn module. It is used to create an instance of a `Long short-term memory (LSTM)` layer."
      ],
      "metadata": {
        "id": "-7i7eSSJCoCu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Key Parameters of nn.LSTM\n",
        "`input_size:`\n",
        "The number of expected features in the input x.\n",
        "\n",
        "`hidden_size:`\n",
        "The number of features in the hidden state h.\n",
        "\n",
        "`num_layers (optional):`\n",
        " Number of recurrent layers. E.g., setting num_layers=2 would mean stacking two LSTMs together to form a stacked LSTM, with the second LSTM taking in outputs of the first LSTM and computing the final results.\n",
        "\n",
        "`bias (optional):`\n",
        " If False, then the layer does not use bias weights b_ih and b_hh. Default is True.\n",
        "\n",
        "`batch_first (optional):`\n",
        " If True, then the input and output tensors are provided as (batch, seq, feature). Default is False, which expects (seq, batch, feature).\n",
        "\n",
        " `dropout (optional):`\n",
        " If non-zero, introduces a Dropout layer on the outputs of each LSTM layer except the last layer, with dropout probability equal to dropout. Default is 0.\n",
        "\n",
        "`bidirectional (optional):`\n",
        " If True, becomes a bidirectional LSTM. Default is False."
      ],
      "metadata": {
        "id": "Lpf9f-4eC2si"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LSTMModel(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_size, output_size):\n",
        "        super(LSTMModel, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)  # Embedding layer\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_size, batch_first=True)  # LSTM layer\n",
        "        self.fc = nn.Linear(hidden_size, output_size)  # Fully connected layer to produce the output\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Embed input words\n",
        "        x = self.embedding(x)\n",
        "        # Initialize hidden state and cell state with zeros\n",
        "        h0 = torch.zeros(1, x.size(0), self.hidden_size)\n",
        "        c0 = torch.zeros(1, x.size(0), self.hidden_size)\n",
        "        # Forward propagate the LSTM\n",
        "        out, (hn, cn) = self.lstm(x, (h0, c0))\n",
        "        # Pass the output of the last time step to the fully connected layer\n",
        "        out = self.fc(out[:, -1, :])\n",
        "        return out\n",
        "\n",
        "# Parameters\n",
        "vocab_size = 10  # Size of the vocabulary (max integer index + 1)\n",
        "embedding_dim = 4  # Dimension of the embedding vectors\n",
        "hidden_size = 10  # Number of features in the hidden state\n",
        "output_size = 1  # Number of output classes\n",
        "\n",
        "# Create the model\n",
        "model = LSTMModel(vocab_size, embedding_dim, hidden_size, output_size)\n",
        "\n",
        "# Loss and optimizer\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "# Sample data (batch size, sequence length)\n",
        "inputs = torch.tensor([[1, 2, 3], [2, 3, 4]])\n",
        "targets = torch.tensor([[4.0], [5.0]])\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(100):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    outputs = model(inputs)\n",
        "    loss =\n"
      ],
      "metadata": {
        "id": "3tZkDJ71Dn9z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Where we want to get the output at every time step.\n",
        "class LSTM2(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_size, output_size):\n",
        "        super(LSTM2, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.rnn = nn.LSTM(embedding_dim, hidden_size, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.embedding(x)\n",
        "        h0 = torch.zeros(1, x.size(0), self.hidden_size)\n",
        "        out, (hn, cn) = self.rnn(x, h0)\n",
        "        # Apply the fully connected layer to all time steps\n",
        "        out = self.fc(out)\n",
        "        return out\n",
        "\n",
        "# Parameters\n",
        "vocab_size = 10  # Size of the vocabulary\n",
        "embedding_dim = 4  # Dimension of the embedding vectors\n",
        "hidden_size = 10  # Number of features in the hidden state\n",
        "output_size = 1  # Number of output classes per timestep\n",
        "\n",
        "# Create the model\n",
        "model = LSTM2(vocab_size, embedding_dim, hidden_size, output_size)\n",
        "\n",
        "# Loss and optimizer\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "# Sample data (batch size, sequence length)\n",
        "inputs = torch.tensor([[1, 2, 3], [2, 3, 4]])\n",
        "targets = torch.tensor([[[4.0], [5.0], [6.0]], [[5.0], [6.0], [7.0]]])\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(100):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    outputs = model(inputs)\n",
        "    loss = criterion(outputs, targets)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if (epoch + 1) % 10 == 0:\n",
        "        print(f'Epoch [{epoch + 1}/100], Loss: {loss.item():.4f}')\n",
        "\n",
        "# Test the model\n",
        "model.eval()\n",
        "test_input = torch.tensor([[3, 4, 5]])\n",
        "predicted = model(test_input)\n",
        "print(f'Predicted values: {predicted.detach().numpy()}')\n"
      ],
      "metadata": {
        "id": "2loPddBQC1g7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LSTMModel2(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_size, output_size):\n",
        "        super(LSTMModel2, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_size, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.embedding(x)\n",
        "        # Initialize hidden state and cell state with zeros\n",
        "        h0 = torch.zeros(1, x.size(0), self.hidden_size)\n",
        "        c0 = torch.zeros(1, x.size(0), self.hidden_size)\n",
        "        # Forward propagate the LSTM\n",
        "        out, (hn, cn) = self.lstm(x, (h0, c0))\n",
        "        # Apply the fully connected layer to all time steps\n",
        "        out = self.fc(out)\n",
        "        return out\n",
        "\n",
        "# Parameters\n",
        "vocab_size = 10  # Size of the vocabulary\n",
        "embedding_dim = 4  # Dimension of the embedding vectors\n",
        "hidden_size = 10  # Number of features in the hidden state\n",
        "output_size = 1  # Number of output classes per timestep\n",
        "\n",
        "# Create the model\n",
        "model = LSTMModel2(vocab_size, embedding_dim, hidden_size, output_size)\n",
        "\n",
        "# Loss and optimizer\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "# Sample data (batch size, sequence length)\n",
        "inputs = torch.tensor([[1, 2, 3], [2, 3, 4]])\n",
        "targets = torch.tensor([[[4.0], [5.0], [6.0]], [[5.0], [6.0], [7.0]]])\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(100):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    outputs = model(inputs)\n",
        "    loss = criterion(outputs, targets)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if (epoch + 1) % 10 == 0:\n",
        "        print(f'Epoch [{epoch + 1}/100], Loss: {loss.item():.4f}')\n",
        "\n",
        "# Test the model\n",
        "model.eval()\n",
        "test_input = torch.tensor([[3, 4, 5]])\n",
        "predicted = model(test_input)\n",
        "print(f'Predicted values: {predicted.detach().numpy()}')\n"
      ],
      "metadata": {
        "id": "UQ16pDilE_Bf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " `nn.Embedding` layer maps each integer in the input sequence to a high-dimensional vector. This layer is particularly useful when dealing with words where each word is represented as a unique integer.\n",
        "\n",
        "`nn.Embedding` layer transforms each integer in the input tensor into an embedding vector. The output shape from the embedding layer becomes (batch_size, sequence_length, embedding_dim).\n",
        "\n",
        " If embedding_dim is 4, as in the example, the shape after the embedding layer will be (2, 3, 4).\n",
        "\n",
        "`LSTM Layer` When this tensor is passed through the nn.LSTM layer, the LSTM processes each sequence of embedded vectors. The nn.LSTM layer outputs three tensors: `the output tensor` , `the hidden state` and `the cell state`. The `output tensor` from the LSTM has the general shape `(batch_size, sequence_length, num_directions * hidden_size)`,both of these `state tensors the cell and the hidden` has the shape `(num_layers * num_directions, batch_size, hidden_size)`.\n",
        "\n",
        "\n",
        "`Fully Connected Layer` the model can uses the output at the last step or at every timestep of the sequence to make a prediction.\n",
        "\n",
        "If we want the prediction at the last time step output is sliced from the LSTM output tensor with `out[:, -1, :]`, which reduces its shape to `(batch_size, hidden_size)`, or (2, 10).the sliced output is then passed through a fully connected layer `(nn.Linear)`, which is designed to map the LSTM's hidden state to the desired output size.\n",
        "\n",
        "\n",
        "If we want the prediction at every time step output no need to slice the RNN output tensor simply pass it to `(nn.Linear)`, which is designed to map the RNN's hidden state to the desired output size.\n"
      ],
      "metadata": {
        "id": "GdXTzzMFFGfg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Parameters\n",
        "input_size = 3\n",
        "hidden_size = 4  # Each direction has 4 features\n",
        "num_layers = 1\n",
        "batch_size = 2\n",
        "seq_length = 5\n",
        "\n",
        "# Create a bidirectional RNN\n",
        "lstm = nn.LSTM(input_size, hidden_size, num_layers=num_layers,\n",
        "             bidirectional=True, batch_first=True)\n",
        "\n",
        "# Example input (batch size, sequence length, input size)\n",
        "input_tensor = torch.randn(batch_size, seq_length, input_size)\n",
        "\n",
        "# Forward pass\n",
        "out, (hn, cn) = lstm(input_tensor)\n",
        "\n",
        "print(\"Output shape (out):\", out.shape)  # Expect [batch_size, seq_length, 2 * hidden_size]\n",
        "print(\"Last hidden state shape (hn):\", hn.shape)  # Expect [2 * num_layers, batch_size, hidden_size]\n",
        "\n",
        "# Output for first batch, first timestep\n",
        "print(\"Forward pass output (first half):\", out[0, 0, :hidden_size])\n",
        "print(\"Backward pass output (second half):\", out[0, 0, hidden_size:])\n"
      ],
      "metadata": {
        "id": "zxkTxAUCIALg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Parameters\n",
        "input_size = 3\n",
        "hidden_size = 4\n",
        "num_layers = 2  # Two layers of LSTM\n",
        "batch_size = 1\n",
        "seq_length = 5\n",
        "bidirectional = True\n",
        "\n",
        "# Define a multi-layer bidirectional LSTM\n",
        "lstm = nn.LSTM(input_size, hidden_size, num_layers=num_layers,\n",
        "               bidirectional=bidirectional, batch_first=True)\n",
        "\n",
        "# Example input tensor\n",
        "input_tensor = torch.randn(batch_size, seq_length, input_size)\n",
        "\n",
        "# Initial hidden and cell states\n",
        "h0 = torch.zeros(num_layers * 2, batch_size, hidden_size)  # 2 for bidirectional\n",
        "c0 = torch.zeros(num_layers * 2, batch_size, hidden_size)\n",
        "\n",
        "# Forward pass through the LSTM\n",
        "out, (hn, cn) = lstm(input_tensor, (h0, c0))\n",
        "\n",
        "print(\"Output shape (out):\", out.shape)  # Expect [batch_size, seq_length, 2 * hidden_size]\n",
        "print(\"Hidden state shape (hn):\", hn.shape)  # Expect [num_layers * num_directions, batch_size, hidden_size]\n",
        "print(\"Cell state shape (cn):\", cn.shape)  # Expect [num_layers * num_directions, batch_size, hidden_size]\n",
        "\n",
        "# Accessing and using the hidden states\n",
        "hn_forward_layer1 = hn[0, :, :]  # First layer, forward direction\n",
        "hn_backward_layer1 = hn[1, :, :]  # First layer, backward direction\n",
        "hn_forward_layer2 = hn[2, :, :]  # Second layer, forward direction\n",
        "hn_backward_layer2 = hn[3, :, :]  # Second layer, backward direction\n",
        "\n",
        "# Example of concatenating forward and backward hidden states for each layer\n",
        "concatenated_layer1 = torch.cat((hn_forward_layer1, hn_backward_layer1), dim=1)\n",
        "concatenated_layer2 = torch.cat((hn_forward_layer2, hn_backward_layer2), dim=1)\n",
        "\n",
        "# Output for verification\n",
        "print(\"Concatenated hidden states, layer 1:\", concatenated_layer1.shape)  # Should be [batch_size, 2*hidden_size]\n",
        "print(\"Concatenated hidden states, layer 2:\", concatenated_layer2.shape)  # Should be [batch_size, 2*hidden_size]\n"
      ],
      "metadata": {
        "id": "D0NGL6KzJH2_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DeepBiLSTM(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_size, output_size, num_layers, output_all_timesteps=False):\n",
        "        super(DeepBiLSTM, self).__init__()\n",
        "        self.output_all_timesteps = output_all_timesteps\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_size, num_layers=num_layers,\n",
        "                            batch_first=True, bidirectional=True)\n",
        "        self.fc = nn.Linear(hidden_size * 2, output_size)  # *2 for bidirectional\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Embedding the input\n",
        "        x = self.embedding(x)\n",
        "        # Default to zero states for hidden and cell states\n",
        "        h0 = torch.zeros(num_layers * 2, x.size(0), self.hidden_size)\n",
        "        c0 = torch.zeros(num_layers * 2, x.size(0), self.hidden_size)\n",
        "        # Forward propagate LSTM\n",
        "        out, (hn, cn) = self.lstm(x, (h0, c0))\n",
        "\n",
        "        if self.output_all_timesteps:\n",
        "            # Apply the fully connected layer to all timesteps\n",
        "            out = self.fc(out)\n",
        "        else:\n",
        "            # Apply the fully connected layer only to the final timestep's output\n",
        "            out = self.fc(out[:, -1, :])\n",
        "\n",
        "        return out\n",
        "\n",
        "# Parameters for the model\n",
        "vocab_size = 100\n",
        "embedding_dim = 50\n",
        "hidden_size = 20\n",
        "output_size = 1\n",
        "num_layers = 2  # More than one layer makes it a deep LSTM\n",
        "\n",
        "# Model instantiation for output at every timestep\n",
        "model_all_timesteps = DeepBiLSTM(vocab_size, embedding_dim, hidden_size, output_size, num_layers, output_all_timesteps=True)\n",
        "\n",
        "# Model instantiation for output at only the last timestep\n",
        "model_last_timestep = DeepBiLSTM(vocab_size, embedding_dim, hidden_size, output_size, num_layers, output_all_timesteps=False)\n",
        "\n",
        "# Example Input\n",
        "input_tensor = torch.tensor([[1, 2, 3, 4], [4, 3, 2, 1]])\n",
        "\n",
        "# Forward pass for both models\n",
        "output_all_timesteps = model_all_timesteps(input_tensor)\n",
        "output_last_timestep = model_last_timestep(input_tensor)\n",
        "\n",
        "print(\"Output (All Timesteps):\", output_all_timesteps.shape)  # (batch_size, sequence_length, output_size)\n",
        "print(\"Output (Last Timestep):\", output_last_timestep.shape)  # (batch_size, output_size)\n"
      ],
      "metadata": {
        "id": "gFJJTGZIGmjw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}