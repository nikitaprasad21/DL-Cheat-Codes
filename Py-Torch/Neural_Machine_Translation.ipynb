{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install indic-nlp-library"
      ],
      "metadata": {
        "id": "kkRxTuOUPObc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o-07RUesRTRH",
        "outputId": "63cad611-1612-4921-b768-a6b7c3b3a484"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchtext\n",
        "import torch.nn.functional as F\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "from torch.utils.data import TensorDataset, DataLoader, random_split\n",
        "from torch.nn.functional import one_hot\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "import os\n",
        "import re\n",
        "import unicodedata\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from indicnlp.tokenize import indic_tokenize"
      ],
      "metadata": {
        "id": "3JRt9DgoIzVC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "en_filepath = \"/content/drive/MyDrive/CampusX_Lecture/Day_5/IITB.en-hi.en\"\n",
        "hi_filepath = \"/content/drive/MyDrive/CampusX_Lecture/Day_5/IITB.en-hi.hi\"\n",
        "\n",
        "with open(en_filepath, \"r\", encoding='utf-8') as f:\n",
        "  english_data = f.readlines()\n",
        "\n",
        "with open(hi_filepath, \"r\", encoding='utf-8') as f:\n",
        "  hindi_data = f.readlines()"
      ],
      "metadata": {
        "id": "SYiAWp0p7CHh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "req_hindi = hindi_data[242929:267939]\n",
        "req_english = english_data[242929:267939]\n",
        "data = {\"english_txt\":req_english,\"hindi_txt\":req_hindi}\n",
        "\n",
        "df = pd.DataFrame(data)"
      ],
      "metadata": {
        "id": "vHq9uIt47tMw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.sample(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "A8y1hR9YHvuU",
        "outputId": "72a7f6dd-8390-4b3a-d5ee-c2c1092a5b4c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                             english_txt  \\\n",
              "23390  Then by oath of those which distribute by the ...   \n",
              "20958  Indeed those who believed and did good deeds –...   \n",
              "12255  And Hell is brought near, that day will man re...   \n",
              "12997  O People who Believe! Do not unjustly devour t...   \n",
              "18984  Would any of you like that he may own a garden...   \n",
              "\n",
              "                                               hindi_txt  \n",
              "23390    फिर एक ज़रूरी चीज़ (बारिश) को तक़सीम करती हैं\\n  \n",
              "20958  बेशक जिन लोगों ने ईमान क़ुबूल किया और अच्छे-अच...  \n",
              "12255  और उस दिन जहन्नुम सामने कर दी जाएगी उस दिन इन्...  \n",
              "12997  ऐ ईमान लानेवालो! आपस में एक-दूसरे के माल ग़लत ...  \n",
              "18984  भला तुम में कोई भी इसको पसन्द करेगा कि उसके लि...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f2850a01-f4cb-4091-b823-e6e146593d24\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>english_txt</th>\n",
              "      <th>hindi_txt</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>23390</th>\n",
              "      <td>Then by oath of those which distribute by the ...</td>\n",
              "      <td>फिर एक ज़रूरी चीज़ (बारिश) को तक़सीम करती हैं\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20958</th>\n",
              "      <td>Indeed those who believed and did good deeds –...</td>\n",
              "      <td>बेशक जिन लोगों ने ईमान क़ुबूल किया और अच्छे-अच...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12255</th>\n",
              "      <td>And Hell is brought near, that day will man re...</td>\n",
              "      <td>और उस दिन जहन्नुम सामने कर दी जाएगी उस दिन इन्...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12997</th>\n",
              "      <td>O People who Believe! Do not unjustly devour t...</td>\n",
              "      <td>ऐ ईमान लानेवालो! आपस में एक-दूसरे के माल ग़लत ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18984</th>\n",
              "      <td>Would any of you like that he may own a garden...</td>\n",
              "      <td>भला तुम में कोई भी इसको पसन्द करेगा कि उसके लि...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f2850a01-f4cb-4091-b823-e6e146593d24')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f2850a01-f4cb-4091-b823-e6e146593d24 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f2850a01-f4cb-4091-b823-e6e146593d24');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-397ed9aa-5075-4a7f-9479-463ed22f300e\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-397ed9aa-5075-4a7f-9479-463ed22f300e')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-397ed9aa-5075-4a7f-9479-463ed22f300e button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"english_txt\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"Indeed those who believed and did good deeds \\u2013 their welcome are the Gardens of Paradise.\\n\",\n          \"Would any of you like that he may own a garden of dates and grapes, with rivers flowing beneath it \\u2013 in it are all kinds of fruits for him \\u2013 and he reaches old age and has young children; therefore a windstorm containing fire came to the garden, burning it? This is how Allah explains His verses to you, so that you may give thought.\\n\",\n          \"And Hell is brought near, that day will man remember, but of what avail will then remembering be?\\n\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"hindi_txt\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"\\u092c\\u0947\\u0936\\u0915 \\u091c\\u093f\\u0928 \\u0932\\u094b\\u0917\\u094b\\u0902 \\u0928\\u0947 \\u0908\\u092e\\u093e\\u0928 \\u0915\\u093c\\u0941\\u092c\\u0942\\u0932 \\u0915\\u093f\\u092f\\u093e \\u0914\\u0930 \\u0905\\u091a\\u094d\\u091b\\u0947-\\u0905\\u091a\\u094d\\u091b\\u0947 \\u0915\\u093e\\u092e \\u0915\\u093f\\u092f\\u0947 \\u0909\\u0928\\u0915\\u0940 \\u092e\\u0947\\u0939\\u092e\\u093e\\u0928\\u0926\\u093e\\u0930\\u0940 \\u0915\\u0947 \\u0932\\u093f\\u090f \\u092b\\u093f\\u0930\\u0926\\u094c\\u0938 (\\u092c\\u0930\\u0940) \\u0915\\u0947 \\u092c\\u093e\\u0917\\u093c\\u093e\\u0924 \\u0939\\u094b\\u0902\\u0917\\u0947 \\u091c\\u093f\\u0928\\u092e\\u0947\\u0902 \\u0935\\u0939 \\u0939\\u092e\\u0947\\u0936\\u093e \\u0930\\u0939\\u0947\\u0902\\u0917\\u0947\\n\",\n          \"\\u092d\\u0932\\u093e \\u0924\\u0941\\u092e \\u092e\\u0947\\u0902 \\u0915\\u094b\\u0908 \\u092d\\u0940 \\u0907\\u0938\\u0915\\u094b \\u092a\\u0938\\u0928\\u094d\\u0926 \\u0915\\u0930\\u0947\\u0917\\u093e \\u0915\\u093f \\u0909\\u0938\\u0915\\u0947 \\u0932\\u093f\\u090f \\u0916\\u091c\\u0942\\u0930\\u094b\\u0902 \\u0914\\u0930 \\u0905\\u0902\\u0917\\u0942\\u0930\\u094b\\u0902 \\u0915\\u093e \\u090f\\u0915 \\u092c\\u093e\\u0917\\u093c \\u0939\\u094b \\u0909\\u0938\\u0915\\u0947 \\u0928\\u0940\\u091a\\u0947 \\u0928\\u0939\\u0930\\u0947\\u0902 \\u091c\\u093e\\u0930\\u0940 \\u0939\\u094b\\u0902 \\u0914\\u0930 \\u0909\\u0938\\u0915\\u0947 \\u0932\\u093f\\u090f \\u0909\\u0938\\u092e\\u0947\\u0902 \\u0924\\u0930\\u0939 \\u0924\\u0930\\u0939 \\u0915\\u0947 \\u092e\\u0947\\u0935\\u0947 \\u0939\\u094b\\u0902 \\u0914\\u0930 (\\u0905\\u092c) \\u0909\\u0938\\u0915\\u094b \\u092c\\u0941\\u0922\\u093c\\u093e\\u092a\\u0947 \\u0928\\u0947 \\u0918\\u0947\\u0930 \\u0932\\u093f\\u092f\\u093e \\u0939\\u0948 \\u0914\\u0930 \\u0909\\u0938\\u0915\\u0947 (\\u091b\\u094b\\u091f\\u0947 \\u091b\\u094b\\u091f\\u0947) \\u0928\\u093e\\u0924\\u0935\\u0949 \\u0915\\u092e\\u091c\\u093c\\u094b\\u0930 \\u092c\\u091a\\u094d\\u091a\\u0947 \\u0939\\u0948\\u0902 \\u0915\\u093f \\u090f\\u0915\\u092c\\u093e\\u0930\\u0917\\u0940 \\u0909\\u0938 \\u092c\\u093e\\u0917\\u093c \\u092a\\u0930 \\u0910\\u0938\\u093e \\u092c\\u0917\\u094b\\u0932\\u093e \\u0906 \\u092a\\u0921\\u093c\\u093e \\u091c\\u093f\\u0938\\u092e\\u0947\\u0902 \\u0906\\u0917 (\\u092d\\u0930\\u0940) \\u0925\\u0940 \\u0915\\u093f \\u0935\\u0939 \\u092c\\u093e\\u0917\\u093c \\u091c\\u0932 \\u092d\\u0941\\u0928 \\u0915\\u0930 \\u0930\\u0939 \\u0917\\u092f\\u093e \\u0916\\u093c\\u0941\\u0926\\u093e \\u0905\\u092a\\u0928\\u0947 \\u090f\\u0939\\u0915\\u093e\\u092e \\u0915\\u094b \\u0924\\u0941\\u092e \\u0932\\u094b\\u0917\\u094b\\u0902 \\u0938\\u0947 \\u0938\\u093e\\u092b\\u093c \\u0938\\u093e\\u092b\\u093c \\u092c\\u092f\\u093e\\u0928 \\u0915\\u0930\\u0924\\u093e \\u0939\\u0948 \\u0924\\u093e\\u0915\\u093f \\u0924\\u0941\\u092e \\u0917\\u093c\\u094c\\u0930 \\u0915\\u0930\\u094b\\n\",\n          \"\\u0914\\u0930 \\u0909\\u0938 \\u0926\\u093f\\u0928 \\u091c\\u0939\\u0928\\u094d\\u0928\\u0941\\u092e \\u0938\\u093e\\u092e\\u0928\\u0947 \\u0915\\u0930 \\u0926\\u0940 \\u091c\\u093e\\u090f\\u0917\\u0940 \\u0909\\u0938 \\u0926\\u093f\\u0928 \\u0907\\u0928\\u094d\\u0938\\u093e\\u0928 \\u091a\\u094c\\u0902\\u0915\\u0947\\u0917\\u093e \\u092e\\u0917\\u0930 \\u0905\\u092c \\u091a\\u094c\\u0902\\u0915\\u0928\\u093e \\u0915\\u0939\\u093e\\u0901 (\\u092b\\u093c\\u093e\\u092f\\u0926\\u093e \\u0926\\u0947\\u0917\\u093e) \\n\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 116
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling the encoding issue by removing the rows.\n",
        "def is_hindi_corrupted(text):\n",
        "    if re.search(r'[^\\u0900-\\u097F\\s,.?!-]', text):\n",
        "        return True\n",
        "    return False"
      ],
      "metadata": {
        "id": "CLMBsn9M_Bo0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply the function to the 'Hindi' column to create a mask\n",
        "df['Corrupted'] = df['hindi_txt'].apply(is_hindi_corrupted)\n",
        "\n",
        "# Filter out corrupted rows\n",
        "df_clean = df[~df['Corrupted']]\n",
        "\n",
        "# Drop the 'Corrupted' column as it's no longer needed\n",
        "df_clean = df_clean.drop(columns=['Corrupted'])"
      ],
      "metadata": {
        "id": "IzYiEZRnHg0E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_clean.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NMKkHxG9Hspq",
        "outputId": "a6ae3957-770f-4b5f-e54d-3d3f7fd3b460"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10512, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_text(text, language=\"english\"):\n",
        "    # Normalize unicode characters\n",
        "    text = unicodedata.normalize('NFKC', text)\n",
        "    # Convert to lowercase if the text is in English\n",
        "    if language == \"english\":\n",
        "        text = text.lower()\n",
        "    # Remove any English words present in Hindi text.\n",
        "    if language == \"hindi\":\n",
        "        text = re.sub('[a-zA-Z]', '', text)\n",
        "    # Remove numbers\n",
        "    text = re.sub(r'\\d+', '', text)\n",
        "    # Remove punctuations\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)\n",
        "    # Remove extra spaces\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "\n",
        "    return text"
      ],
      "metadata": {
        "id": "-kq-NSH9yvuy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_clean[\"english_txt\"] = df_clean[\"english_txt\"].apply(clean_text)\n",
        "df_clean[\"hindi_txt\"] = df_clean['hindi_txt'].apply(clean_text, args=(\"hindi\",))"
      ],
      "metadata": {
        "id": "h-uvkUye8g8o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_clean.sample(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "nKFtG_obLh84",
        "outputId": "aafaf18f-413b-454b-a169-33742f2fcd81"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                             english_txt  \\\n",
              "11823                then he strutted back to his people   \n",
              "13742  they wish to extinguish the light of allah wit...   \n",
              "16574  we have indeed sent down this book to you with...   \n",
              "4026   this is what is promised you for the day of re...   \n",
              "1606   in the story of joseph and his brothers are le...   \n",
              "15290  on the day when their tongues and their hands ...   \n",
              "18221    so when the greatest universal disaster arrives   \n",
              "3044   i ask no recompense of you for it my reward is...   \n",
              "3098                        so fear god and listen to me   \n",
              "5714   that day is certain so whosoever likes may pre...   \n",
              "\n",
              "                                               hindi_txt  \n",
              "11823                            अपन घर क तरफ इतरत हआ चल  \n",
              "13742  चहत ह क अललह क परकश क अपन मह स बझ द कनत अललह अ...  \n",
              "16574  नशचय ह हमन लग क लए हक क सथ तमपर कतब अवतरत क ह ...  \n",
              "4026         यह ह वह चज जसक हसब क दन क लए तमस वद कय जत ह  \n",
              "1606       नशचय ह यसफ और उनक भइय म सवल करनवल क लए नशनय ह  \n",
              "15290  जस दन क उनक जबन और उनक हथ और उनक पव उनक वरदध उ...  \n",
              "18221                                 फर जब वह महवपद आएग  \n",
              "3044   म इस कम क बदल तमस कई बदल नह मगत मर बदल त बस सर...  \n",
              "3098                  अत अललह क डर रख और मर आजञ क पलन कर  \n",
              "5714            वह दन सतय ह अब ज कई चह अपन रब क ओर रज कर  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1ca8fae2-e7a9-4da4-afc6-b12d355aa0ca\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>english_txt</th>\n",
              "      <th>hindi_txt</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>11823</th>\n",
              "      <td>then he strutted back to his people</td>\n",
              "      <td>अपन घर क तरफ इतरत हआ चल</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13742</th>\n",
              "      <td>they wish to extinguish the light of allah wit...</td>\n",
              "      <td>चहत ह क अललह क परकश क अपन मह स बझ द कनत अललह अ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16574</th>\n",
              "      <td>we have indeed sent down this book to you with...</td>\n",
              "      <td>नशचय ह हमन लग क लए हक क सथ तमपर कतब अवतरत क ह ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4026</th>\n",
              "      <td>this is what is promised you for the day of re...</td>\n",
              "      <td>यह ह वह चज जसक हसब क दन क लए तमस वद कय जत ह</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1606</th>\n",
              "      <td>in the story of joseph and his brothers are le...</td>\n",
              "      <td>नशचय ह यसफ और उनक भइय म सवल करनवल क लए नशनय ह</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15290</th>\n",
              "      <td>on the day when their tongues and their hands ...</td>\n",
              "      <td>जस दन क उनक जबन और उनक हथ और उनक पव उनक वरदध उ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18221</th>\n",
              "      <td>so when the greatest universal disaster arrives</td>\n",
              "      <td>फर जब वह महवपद आएग</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3044</th>\n",
              "      <td>i ask no recompense of you for it my reward is...</td>\n",
              "      <td>म इस कम क बदल तमस कई बदल नह मगत मर बदल त बस सर...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3098</th>\n",
              "      <td>so fear god and listen to me</td>\n",
              "      <td>अत अललह क डर रख और मर आजञ क पलन कर</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5714</th>\n",
              "      <td>that day is certain so whosoever likes may pre...</td>\n",
              "      <td>वह दन सतय ह अब ज कई चह अपन रब क ओर रज कर</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1ca8fae2-e7a9-4da4-afc6-b12d355aa0ca')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-1ca8fae2-e7a9-4da4-afc6-b12d355aa0ca button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-1ca8fae2-e7a9-4da4-afc6-b12d355aa0ca');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-513b43ce-56b5-48f6-a200-d8e142160e65\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-513b43ce-56b5-48f6-a200-d8e142160e65')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-513b43ce-56b5-48f6-a200-d8e142160e65 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"df_clean\",\n  \"rows\": 10,\n  \"fields\": [\n    {\n      \"column\": \"english_txt\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"so fear god and listen to me\",\n          \"they wish to extinguish the light of allah with their mouths but allah will not agree except that he will perfect his light even if the disbelievers get annoyed\",\n          \"on the day when their tongues and their hands and their feet will testify against them regarding what they used to do\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"hindi_txt\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"\\u0905\\u0924 \\u0905\\u0932\\u0932\\u0939 \\u0915 \\u0921\\u0930 \\u0930\\u0916 \\u0914\\u0930 \\u092e\\u0930 \\u0906\\u091c\\u091e \\u0915 \\u092a\\u0932\\u0928 \\u0915\\u0930\",\n          \"\\u091a\\u0939\\u0924 \\u0939 \\u0915 \\u0905\\u0932\\u0932\\u0939 \\u0915 \\u092a\\u0930\\u0915\\u0936 \\u0915 \\u0905\\u092a\\u0928 \\u092e\\u0939 \\u0938 \\u092c\\u091d \\u0926 \\u0915\\u0928\\u0924 \\u0905\\u0932\\u0932\\u0939 \\u0905\\u092a\\u0928 \\u092a\\u0930\\u0915\\u0936 \\u0915 \\u092a\\u0930\\u0923 \\u0915\\u090f \\u092c\\u0928 \\u0928\\u0939 \\u0930\\u0939\\u0917 \\u091a\\u0939 \\u0907\\u0928\\u0915\\u0930 \\u0915\\u0930\\u0928\\u0935\\u0932 \\u0915 \\u0905\\u092a\\u0930\\u092f \\u0939 \\u0932\\u0917\",\n          \"\\u091c\\u0938 \\u0926\\u0928 \\u0915 \\u0909\\u0928\\u0915 \\u091c\\u092c\\u0928 \\u0914\\u0930 \\u0909\\u0928\\u0915 \\u0939\\u0925 \\u0914\\u0930 \\u0909\\u0928\\u0915 \\u092a\\u0935 \\u0909\\u0928\\u0915 \\u0935\\u0930\\u0926\\u0927 \\u0909\\u0938\\u0915 \\u0917\\u0935\\u0939 \\u0926\\u0917 \\u091c \\u0915\\u091b \\u0935 \\u0915\\u0930\\u0924 \\u0930\\u0939 \\u0925\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 122
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_clean['English_Words'] = df_clean['english_txt'].apply(lambda x: len(x.split()))\n",
        "df_clean['Hindi_Words'] = df_clean['hindi_txt'].apply(lambda x: len(x.split()))"
      ],
      "metadata": {
        "id": "5-j5YrNJLxid"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate averages\n",
        "average_english_words = df_clean['English_Words'].quantile(.99)\n",
        "average_hindi_words = df_clean['Hindi_Words'].quantile(.99)\n",
        "\n",
        "# Data for plotting\n",
        "averages = [average_english_words, average_hindi_words]\n",
        "languages = ['English', 'Hindi']\n",
        "\n",
        "# Creating the plot\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.bar(languages, averages, color=['blue', 'red'])\n",
        "plt.xlabel('Language')\n",
        "plt.ylabel('Number of Words per Sentence')\n",
        "plt.title('Comparison of Number of Words Counts in English and Hindi')\n",
        "plt.ylim(0, max(averages) + 1)  # Adjust y-axis for better visualization\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "NpOd55hIL7DA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Torchtext\n",
        "Torchtext is a library within the PyTorch ecosystem designed to facilitate the preprocessing of textual data.\n",
        "\n",
        "## get_tokenizer\n",
        ". The get_tokenizer function is one of the core utilities provided by torchtext for tokenizing text data.\n",
        "\n",
        ". get_tokenizer retrieves a tokenizer function based on the method specified. This tokenizer can then be used to convert strings of text into lists of tokens.\n",
        "##Parameters\n",
        "  \n",
        "  tokenizer: This argument specifies the type of tokenizer to use. You can specify built-in tokenizers such as \"basic_english\", \"spacy\", \"moses\", or even provide a custom tokenizer function.\n",
        "\n",
        "  language: Some tokenizers, like those based on the Moses or Spacy libraries, might require you to specify the language of the text, which influences how the text is tokenized (e.g., handling language-specific punctuation and splitting rules)."
      ],
      "metadata": {
        "id": "UIFPGpu36sSl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer_eng = get_tokenizer('basic_english')\n",
        "tokenizer_hin = indic_tokenize.trivial_tokenize  # This is the Hindi tokenizer from Indic NLP\n",
        "\n",
        "tokenized_english_txt = [tokenizer_eng(english_sen) for english_sen in df_clean['english_txt'] ]\n",
        "tokenized_hindi_txt = [tokenizer_hin(hindi_sen) for hindi_sen in df_clean['hindi_txt'] ]"
      ],
      "metadata": {
        "id": "SzBeCo8MOcwE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenized_english_txt[9])\n",
        "print(tokenized_hindi_txt[9])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "khwzrttoOFjp",
        "outputId": "25edbdad-338c-49f2-b388-63f180d4ca01"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['the', 'path', 'of', 'those', 'you', 'have', 'blessed', 'not', 'of', 'those', 'who', 'have', 'earned', 'your', 'anger', 'nor', 'those', 'who', 'have', 'gone', 'astray']\n",
            "['उन', 'लग', 'क', 'मरग', 'पर', 'ज', 'तर', 'कपपतर', 'हए', 'ज', 'न', 'परकप', 'क', 'भग', 'हए', 'और', 'न', 'पथभरषट']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## build_vocab_from_iterator\n",
        "`build_vocab_from_iterator` function in the torchtext.vocab module is used to create a vocabulary from an iterable of tokenized data. This vocabulary is essential for converting textual data into numerical form.\n",
        "\n",
        "#Parameters:\n",
        "##tokenized_conv (iterator):\n",
        "This is the main data input to the function. It should be an iterator (like a `generator` or a `list`) that yields sequences of tokens. Each sequence represents a document or an example in your dataset.\n",
        "##min_freq (int, optional):\n",
        " This parameter specifies the minimum frequency a token must have to be included in the vocabulary. Tokens that appear fewer than min_freq times are excluded from the vocabulary. This is useful for removing rare words which might be typos or irrelevant to most analyses.\n",
        "##specials (list of str, optional):\n",
        " This is a list of special tokens that you want to add to the vocabulary. Common special tokens include:\n",
        "'<pad>': A padding token used to equalize the lengths of sequences.\n",
        "'<oov>' (or '<unk>' for \"unknown\"): A token used to represent out-of-vocabulary words during inference, or when a word appears that is not in the training vocabulary.\n",
        "##special_first (bool, optional):\n",
        " Determines the ordering of special tokens in the vocabulary. If True, special tokens are added at the beginning of the vocabulary. This can be helpful for certain models where token indices are significant (e.g., models using embedding layers might have specific handling for lower indices)."
      ],
      "metadata": {
        "id": "h4TytNjp6xKC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3: Building Vocabulary\n",
        "features_vocab = torchtext.vocab.build_vocab_from_iterator(tokenized_english_txt, specials=['<unk>', '<pad>', '<bos>', '<eos>'])\n",
        "target_vocab = torchtext.vocab.build_vocab_from_iterator(tokenized_hindi_txt, specials=['<unk>', '<pad>', '<bos>', '<eos>'])\n",
        "\n",
        "features_vocab.set_default_index(features_vocab['<unk>'])\n",
        "target_vocab.set_default_index(target_vocab['<unk>'])"
      ],
      "metadata": {
        "id": "upBTp-UJS9xC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features_vocab_total_words = len(features_vocab)\n",
        "target_vocab_total_words = len(target_vocab)"
      ],
      "metadata": {
        "id": "CkkIj_XFLjWw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(features_vocab_total_words)  #English\n",
        "print(target_vocab_total_words)    #Hindi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v5bIQHZuJXMS",
        "outputId": "9d60e452-d462-4a53-9ccc-935cd29e4299"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6544\n",
            "4083\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "features_vocab['<bos>']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ttQaYjVnpOh1",
        "outputId": "91941076-4ece-4485-ce9a-34bc56718f86"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 132
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(features_vocab_total_words)\n",
        "print(target_vocab_total_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XnTdkafdLmNO",
        "outputId": "fb627fbb-5b51-4fb9-b820-d4642f7538f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6544\n",
            "4083\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def tokens_to_indices(tokenized_texts, vocab):\n",
        "    indices_texts = []\n",
        "    for sentence in tokenized_texts:\n",
        "        indices_texts.append([vocab[token] for token in sentence if token in vocab])\n",
        "    return indices_texts"
      ],
      "metadata": {
        "id": "uvUtpWeDLt_g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "english_indices = tokens_to_indices(tokenized_english_txt, features_vocab)\n",
        "hindi_indices = tokens_to_indices(tokenized_hindi_txt, target_vocab)"
      ],
      "metadata": {
        "id": "t1pH9g5XM-Nf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "english_indices[0:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tZMYCBAxJ-aB",
        "outputId": "cd3ed0b6-daf7-496f-e93b-55ba741d6fd4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[5057, 4617],\n",
              " [4617, 8, 3848, 8],\n",
              " [3848, 192, 11, 5764],\n",
              " [11, 4, 349, 6, 24, 72, 1376, 197, 173],\n",
              " [36, 329, 27, 8, 24, 38, 6, 36, 4, 561],\n",
              " [72, 1593, 197, 173],\n",
              " [1063, 6, 4, 44, 6, 257],\n",
              " [7, 436, 18, 139, 5, 8, 7, 436, 125, 15, 215],\n",
              " [301, 93, 55, 38, 8, 4, 131, 21, 9, 242],\n",
              " [4,\n",
              "  131,\n",
              "  6,\n",
              "  26,\n",
              "  7,\n",
              "  29,\n",
              "  537,\n",
              "  17,\n",
              "  6,\n",
              "  26,\n",
              "  13,\n",
              "  29,\n",
              "  524,\n",
              "  31,\n",
              "  1164,\n",
              "  77,\n",
              "  26,\n",
              "  13,\n",
              "  29,\n",
              "  431,\n",
              "  193]]"
            ]
          },
          "metadata": {},
          "execution_count": 135
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class TranslationDataset(Dataset):\n",
        "    def __init__(self, english_data, hindi_data):\n",
        "        self.english_data = english_data\n",
        "        self.hindi_data = hindi_data\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.english_data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        english = torch.tensor(self.english_data[idx], dtype=torch.long)\n",
        "        hindi = torch.tensor(self.hindi_data[idx], dtype=torch.long)\n",
        "        return english, hindi\n",
        "\n",
        "# Create the custom dataset\n",
        "dataset = TranslationDataset(english_indices, hindi_indices)\n",
        "FIXED_LENGTH = 60  # or any appropriate length based on your data or model requirements\n"
      ],
      "metadata": {
        "id": "Ohf0O1CnM-Qf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Purpose of collate_fn\n",
        "The primary purpose of `collate_fn` is to dynamically decide how to combine multiple data samples into a single batch. Data samples can be anything from images, texts, or other forms of data, and they might not naturally fit together in a straightforward way (e.g., texts of varying lengths)."
      ],
      "metadata": {
        "id": "TP8Dy_V67dyj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def collate_batch(batch):\n",
        "    english_batch, hindi_batch = zip(*batch)\n",
        "\n",
        "    # Pad or truncate English batch\n",
        "    english_batch = [torch.tensor(seq[:FIXED_LENGTH], dtype=torch.long) if len(seq) > FIXED_LENGTH else torch.cat([torch.tensor(seq, dtype=torch.long), torch.full((FIXED_LENGTH - len(seq),), features_vocab['<pad>'], dtype=torch.long)]) for seq in english_batch]\n",
        "\n",
        "    # Pad or truncate Hindi batch\n",
        "    hindi_batch = [torch.tensor(seq[:FIXED_LENGTH], dtype=torch.long) if len(seq) > FIXED_LENGTH else torch.cat([torch.tensor(seq, dtype=torch.long), torch.full((FIXED_LENGTH - len(seq),), target_vocab['<pad>'], dtype=torch.long)]) for seq in hindi_batch]\n",
        "\n",
        "    # Convert lists to tensors\n",
        "    english_batch = torch.stack(english_batch)\n",
        "    hindi_batch = torch.stack(hindi_batch)\n",
        "\n",
        "    return english_batch, hindi_batch\n"
      ],
      "metadata": {
        "id": "KBEn7e-NcxkF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32  # Adjust the batch size as needed\n",
        "train_dataloader = DataLoader(dataset, batch_size=batch_size, collate_fn=collate_batch, shuffle=True)"
      ],
      "metadata": {
        "id": "TDhltO-xc1zM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "bs67MOd8achu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wytwBPlbV0Sk",
        "outputId": "0fcfe741-dde5-4b24-a6a8-b5ee33e3d87a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample = next(iter(train_dataloader))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2D7ndzj28Siv",
        "outputId": "a274a9cb-6df8-4ea1-d25a-44998e3ce9c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-137-6d92b6dff899>:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  english_batch = [torch.tensor(seq[:FIXED_LENGTH], dtype=torch.long) if len(seq) > FIXED_LENGTH else torch.cat([torch.tensor(seq, dtype=torch.long), torch.full((FIXED_LENGTH - len(seq),), features_vocab['<pad>'], dtype=torch.long)]) for seq in english_batch]\n",
            "<ipython-input-137-6d92b6dff899>:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  hindi_batch = [torch.tensor(seq[:FIXED_LENGTH], dtype=torch.long) if len(seq) > FIXED_LENGTH else torch.cat([torch.tensor(seq, dtype=torch.long), torch.full((FIXED_LENGTH - len(seq),), target_vocab['<pad>'], dtype=torch.long)]) for seq in hindi_batch]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample[0].size()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yMf18HtM8X0q",
        "outputId": "14a384dc-2988-49a7-f4a3-839edafd84cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 60])"
            ]
          },
          "metadata": {},
          "execution_count": 142
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "`get_itos`: stands for \"index-to-string\". The method returns a list where the indices in the list correspond to the numerical indices used in your model, and the values at those indices are the actual string representations (tokens)."
      ],
      "metadata": {
        "id": "MFD66slv7OYw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class EncoderRNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, dropout_p=0.1):\n",
        "        super(EncoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size, batch_first=True)\n",
        "        self.dropout = nn.Dropout(dropout_p)\n",
        "\n",
        "    def forward(self, input):    #[4,8,9,15,12]\n",
        "        embedded = self.dropout(self.embedding(input))\n",
        "        output, hidden = self.gru(embedded)\n",
        "        return output, hidden"
      ],
      "metadata": {
        "id": "aUv5MU5RM-UG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BahdanauAttention(nn.Module):\n",
        "    def __init__(self, hidden_size):\n",
        "        super(BahdanauAttention, self).__init__()\n",
        "\n",
        "        self.Wa = nn.Linear(hidden_size, hidden_size)   # Transform for query\n",
        "        self.Ua = nn.Linear(hidden_size, hidden_size)   # Transform for keys\n",
        "        self.Va = nn.Linear(hidden_size, 1)   # Compute the attention score\n",
        "\n",
        "    def forward(self, query, keys):\n",
        "        # Expand query to match keys' batch and sequence dimension\n",
        "        # Encoder Output i.e key Shape (batch, seq_len, hidden_dim) when batch_first = True\n",
        "        # Hidden State of Decoder i.e query shape (num_dir*num_layers, batch, hidden_dim)\n",
        "\n",
        "        # Since Decoder Queries about the information to encoder on which token to focus when generating the current token\n",
        "        # we need to replecate the decoder Hidden State along the encoder output to get score for each output.\n",
        "        key_shape = keys.size()\n",
        "\n",
        "        query = query.repeat(1, key_shape[1], 1)\n",
        "        scores = self.Va(torch.tanh(self.Wa(query) + self.Ua(keys)))  # attn_score = VT.(tanh(Wa*s|encoder + Ua|decoder + bias))\n",
        "        scores = scores.squeeze(-1)\n",
        "\n",
        "        weights = torch.softmax(scores, dim=1)\n",
        "        weights = weights.unsqueeze(1)\n",
        "        context = torch.bmm(weights, keys)\n",
        "\n",
        "        return context, weights\n",
        "\n",
        "class AttnDecoderRNN(nn.Module):\n",
        "    def __init__(self, hidden_size, output_size, dropout_p=0.1):\n",
        "        super(AttnDecoderRNN, self).__init__()\n",
        "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
        "        self.attention = BahdanauAttention(hidden_size)\n",
        "        self.gru = nn.GRU(2 * hidden_size, hidden_size, batch_first=True)\n",
        "        self.out = nn.Linear(hidden_size, output_size)\n",
        "        self.dropout = nn.Dropout(dropout_p)\n",
        "\n",
        "    def forward(self, encoder_outputs, encoder_hidden, target_tensor=None):\n",
        "        batch_size = encoder_outputs.size(0)\n",
        "\n",
        "        bos_token_index = features_vocab['<bos>']\n",
        "        decoder_input = torch.full((batch_size, 1), bos_token_index, dtype=torch.long, device=device)\n",
        "        decoder_hidden = encoder_hidden\n",
        "        decoder_outputs = []\n",
        "        attentions = []\n",
        "        # fixed length set to 60\n",
        "        for i in range(60):\n",
        "            decoder_output, decoder_hidden, attn_weights = self.forward_step(\n",
        "                decoder_input, decoder_hidden, encoder_outputs\n",
        "            )\n",
        "            decoder_outputs.append(decoder_output)\n",
        "            attentions.append(attn_weights)\n",
        "\n",
        "            if target_tensor is not None:\n",
        "                # Teacher forcing: Feed the target as the next input\n",
        "                decoder_input = target_tensor[:, i].unsqueeze(1) # Teacher forcing\n",
        "            else:\n",
        "                # Without teacher forcing: use its own predictions as the next input\n",
        "                _, topi = decoder_output.topk(1)\n",
        "                decoder_input = topi.squeeze(-1).detach()  # detach from history as input\n",
        "\n",
        "        decoder_outputs = torch.cat(decoder_outputs, dim=1)\n",
        "        decoder_outputs = F.log_softmax(decoder_outputs, dim=-1)\n",
        "        attentions = torch.cat(attentions, dim=1)\n",
        "\n",
        "        return decoder_outputs, decoder_hidden, attentions\n",
        "\n",
        "\n",
        "    def forward_step(self, input, hidden, encoder_outputs):\n",
        "        embedded =  self.dropout(self.embedding(input))\n",
        "\n",
        "        query = hidden.permute(1, 0, 2)    # this is the shape of [num_layers * num_directions, batch_size, hidden_size]\n",
        "                                            # encoder output [batch_size, seq_len, hidden_size]\n",
        "        context, attn_weights = self.attention(query, encoder_outputs)\n",
        "        input_gru = torch.cat((embedded, context), dim=2)\n",
        "\n",
        "        output, hidden = self.gru(input_gru, hidden)\n",
        "        output = self.out(output)\n",
        "\n",
        "        return output, hidden, attn_weights"
      ],
      "metadata": {
        "id": "SOZQffs_aOrQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.switch_backend('agg')\n",
        "import matplotlib.ticker as ticker\n",
        "import numpy as np\n",
        "\n",
        "def showPlot(points):\n",
        "    plt.figure()\n",
        "    fig, ax = plt.subplots()\n",
        "    # this locator puts ticks at regular intervals\n",
        "    loc = ticker.MultipleLocator(base=0.2)\n",
        "    ax.yaxis.set_major_locator(loc)\n",
        "    plt.plot(points)"
      ],
      "metadata": {
        "id": "I53ihZ7Jfiab"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(train_dataloader, encoder, decoder, n_epochs, learning_rate=0.001,\n",
        "               print_every=5, plot_every=5, save_every=5, save_path = \"/content/drive/MyDrive/CampusX_Lecture/Day_5/\"):\n",
        "    start = time.time()\n",
        "    plot_losses = []\n",
        "    print_loss_total = 0  # Reset every print_every\n",
        "    plot_loss_total = 0  # Reset every plot_every\n",
        "\n",
        "    encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
        "    decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate)\n",
        "    criterion = nn.NLLLoss()\n",
        "\n",
        "    for epoch in range(1, n_epochs + 1):\n",
        "        loss = train_epoch(train_dataloader, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
        "        print_loss_total += loss\n",
        "        plot_loss_total += loss\n",
        "\n",
        "        if epoch % print_every == 0:\n",
        "            print_loss_avg = print_loss_total / print_every\n",
        "            print_loss_total = 0\n",
        "            print('%s (%d %d%%) %.4f' % (timeSince(start, epoch / n_epochs),\n",
        "                                        epoch, epoch / n_epochs * 100, print_loss_avg))\n",
        "\n",
        "        if epoch % plot_every == 0:\n",
        "            plot_loss_avg = plot_loss_total / plot_every\n",
        "            plot_losses.append(plot_loss_avg)\n",
        "            plot_loss_total = 0\n",
        "\n",
        "        if epoch % save_every == 0:\n",
        "            encoder_save_path = os.path.join(save_path, f'/content/drive/MyDrive/CampusX_Lecture/Day_5/encoder_epoch_{epoch}.pth')\n",
        "            decoder_save_path = os.path.join(save_path, f'/content/drive/MyDrive/CampusX_Lecture/Day_5/decoder_epoch_{epoch}.pth')\n",
        "            torch.save(encoder.state_dict(), encoder_save_path)\n",
        "            torch.save(decoder.state_dict(), decoder_save_path)\n",
        "            print(f'Model saved at epoch {epoch}')\n",
        "    showPlot(plot_losses)"
      ],
      "metadata": {
        "id": "uHBcirVDfidT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import math\n",
        "\n",
        "def asMinutes(s):\n",
        "    m = math.floor(s / 60)\n",
        "    s -= m * 60\n",
        "    return '%dm %ds' % (m, s)\n",
        "\n",
        "def timeSince(since, percent):\n",
        "    now = time.time()\n",
        "    s = now - since\n",
        "    es = s / (percent)\n",
        "    rs = es - s\n",
        "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
      ],
      "metadata": {
        "id": "rzuTOQJ8ffI4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_epoch(dataloader, encoder, decoder, encoder_optimizer,\n",
        "          decoder_optimizer, criterion):\n",
        "\n",
        "    total_loss = 0\n",
        "    for data in dataloader:\n",
        "        input_tensor, target_tensor = data\n",
        "        input_tensor, target_tensor = input_tensor.to(device), target_tensor.to(device)\n",
        "        encoder_optimizer.zero_grad()\n",
        "        decoder_optimizer.zero_grad()\n",
        "\n",
        "        encoder_outputs, encoder_hidden = encoder(input_tensor)\n",
        "        decoder_outputs, _, _ = decoder(encoder_outputs, encoder_hidden, target_tensor)\n",
        "\n",
        "        loss = criterion(\n",
        "            decoder_outputs.view(-1, decoder_outputs.size(-1)),\n",
        "            target_tensor.view(-1)\n",
        "        )\n",
        "        loss.backward()\n",
        "\n",
        "        encoder_optimizer.step()\n",
        "        decoder_optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    return total_loss / len(dataloader)"
      ],
      "metadata": {
        "id": "E96KOEbPfW1T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hidden_size = 128\n",
        "batch_size = 32\n",
        "features_vocab_total_words = len(features_vocab)\n",
        "target_vocab_total_words = len(target_vocab)\n",
        "\n",
        "encoder = EncoderRNN(features_vocab_total_words, hidden_size).to(device)\n",
        "decoder = AttnDecoderRNN(hidden_size, target_vocab_total_words).to(device)"
      ],
      "metadata": {
        "id": "E3J8fUnzfiHK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train(train_dataloader, encoder, decoder, n_epochs = 50, print_every=5, plot_every=5)"
      ],
      "metadata": {
        "id": "kNAVKmc3jxWf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gqgxfDWKvwOH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5WFNozta2sdY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder.load_state_dict(torch.load(\"/content/drive/MyDrive/CampusX_Lecture/Day_5/encoder_epoch_45.pth\"))\n",
        "decoder.load_state_dict(torch.load(\"/content/drive/MyDrive/CampusX_Lecture/Day_5/decoder_epoch_45.pth\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zTqoulmIj1Bv",
        "outputId": "9b25ff98-1d81-4e11-9758-a909793df7d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(encoder, decoder, sentence, feature_vocab, target_vocab):\n",
        "    with torch.no_grad():\n",
        "\n",
        "        tokenized_english_txt_test = tokenizer_eng(sentence)\n",
        "        english_indices_test = tokens_to_indices(tokenized_english_txt_test, features_vocab)\n",
        "        input_tensor = torch.LongTensor(english_indices_test).to(device).reshape(1,4)\n",
        "\n",
        "        encoder_outputs, encoder_hidden = encoder(input_tensor)\n",
        "        decoder_outputs, decoder_hidden, decoder_attn = decoder(encoder_outputs, encoder_hidden)\n",
        "\n",
        "        _, topi = decoder_outputs.topk(1)\n",
        "        decoded_ids = topi.squeeze()\n",
        "\n",
        "        EOS_token = feature_vocab['<eos>']\n",
        "        decoded_words = []\n",
        "        for idx in decoded_ids:\n",
        "            if idx.item() == EOS_token:\n",
        "                decoded_words.append('<eos>')\n",
        "                break\n",
        "            decoded_words.append(target_vocab.get_itos()[idx] if idx < len(target_vocab) else '<unk>')\n",
        "    return decoded_words, decoder_attn"
      ],
      "metadata": {
        "id": "RBihHux53ta0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = \"Hi How are you\"\n",
        "decoder_output, attn_weights = evaluate(encoder, decoder, sentence, features_vocab, target_vocab)"
      ],
      "metadata": {
        "id": "ULRF2SUm3rGT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def indices_to_words(indices, vocab):\n",
        "#     return [vocab.get_itos()[index] if index < len(vocab) else '<unk>' for index in indices]"
      ],
      "metadata": {
        "id": "vUQNMln-zNaK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}