{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# What is RNN?\n",
        "\n",
        "A recurrent neural network (RNN) is a deep learning model that is trained to process and convert a sequential data input into a specific sequential data output.\n",
        "\n",
        "## What is Seqential Data?\n",
        "\n",
        " Sequential data is data—such as words, sentences, audio (Speech) or time-series data—where sequential components are interrelate based on complex semantics and syntax rules.\n",
        "\n",
        "## What are the types of recurrent neural networks?\n",
        "\n",
        "The following are several common RNN types.\n",
        "\n",
        "* **One-to-Many RNNs**: In this architecture, the RNN receives a single input at the beginning (the \"one\" part), and then it generates a sequence of outputs (the \"many\" part).\n",
        "\n",
        "   - This can be useful for tasks such as image captioning, where the input is an image, and the output is a sequence of words describing the content of the image.\n",
        "   - **Example**: *In image captioning, the RNN receives an image as input and generates a sequence of words to describe the contents of the image.*\n",
        "\n",
        "* **Many-to-One RNNs**: Conversely, in many-to-one RNNs, the network receives a sequence of inputs (the \"many\" part) and produces a single output (the \"one\" part).\n",
        "   - This setup is commonly used for tasks like sentiment analysis, where the input is a sequence of words, and the output is a sentiment label (positive or negative).\n",
        "   - **Example**: *In sentiment analysis, the RNN receives a sequence of words representing a movie review and predicts whether the sentiment is positive, negative, and neutral from input reviews*\n",
        "* **Many-to-Many RNNs (Sequence-to-Sequence)**: In this architecture, the RNN takes a sequence of inputs and produces a sequence of outputs, can be of variable lengths.\n",
        "\n",
        "   - This setup is used for tasks such as machine translation, where the input is a sequence of words in one language, and the output is a sequence of words in another language.\n",
        "   - **Example**: *In machine translation, the RNN receives a sequence of words in English and generates a sequence of words in French.*\n",
        "\n",
        "* **Many-to-Many (Synced) RNNs**: In this variant of many-to-many RNNs, the input and output sequences have the same length.\n",
        "\n",
        "   - This architecture is used for tasks like named entity recognition (NER), where the input is a sequence of words, and the output is a sequence of labels indicating named entities.\n",
        "   - **Example**: *In named entity recognition, the RNN receives a sequence of words and generates a sequence of labels indicating whether each word is part of a named entity (e.g., person, organization, location).*\n",
        "\n",
        "\n",
        "### What about One-to-One?\n",
        "\n",
        "While the \"one-to-one\" architecture is straightforward (each input is processed independently, and there are no recurrent connections or feedback loops.) and suitable for certain types of tasks, it doesn't leverage the sequential nature of data or capture temporal dependencies, which are essential for tasks like sequence prediction, time series forecasting, or natural language processing.\n",
        "\n",
        "   - This architecture is used for tasks like simple classification tasks, regression tasks, or tasks where each input represents a standalone instance.\n",
        "\n",
        "   - **Example**: *Suppose you have a dataset of images, and each image is associated with a single label indicating the object in the image. You can train a \"one-to-one\" neural network to classify each image into its respective category without considering any sequential or temporal information.*"
      ],
      "metadata": {
        "id": "9jzHlvfveOoP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## How RNN Model Works?\n",
        "\n",
        "Unlike feedforward neural networks, which process each input independently,\n",
        "\n",
        "RNNs maintain an **internal state (memory)** that allows them to *capture temporal dependencies and patterns in sequential data*.\n",
        "\n",
        "\n",
        "\n",
        "* **Sequential Input**: RNNs take sequential input data, such as text, time series, or audio, where the order of the elements matters. Each element in the sequence is typically represented as a vector or a sequence of feature vectors.\n",
        "\n",
        "* **Recurrent Connections**: RNNs have recurrent connections that allow information to persist over time steps. At each time step, the RNN processes an input vector and updates its internal state based on both the current input and the previous state.\n",
        "\n",
        "* **Hidden State Update**: At each time step 𝑡, the RNN computes a new hidden state\n",
        "ℎ\n",
        "𝑡 using the current input\n",
        "𝑥\n",
        "𝑡\n",
        " and the previous hidden state\n",
        "ℎ\n",
        "𝑡\n",
        "−\n",
        "1\n",
        ". This hidden state serves as a summary of the information processed so far and is passed to the next time step.\n",
        "\n",
        "\n",
        "## **ℎ 𝑡 = 𝑓(𝑊 ℎ ⋅ ℎ 𝑡−1 + 𝑊 𝑥 ⋅𝑥 𝑡 + 𝑏)**\n",
        "\n",
        "\n",
        "where:\n",
        "\n",
        "* ℎ\n",
        "𝑡 is the hidden state at time step 𝑡\n",
        "\n",
        "* 𝑓 is the activation function (e.g., tanh or ReLU)\n",
        "\n",
        "* 𝑊\n",
        "ℎ\n",
        "is the weight matrix for the recurrent connections\n",
        "\n",
        "* 𝑊\n",
        "𝑥\n",
        " is the weight matrix for the input connections\n",
        "\n",
        "* 𝑏 is the bias vector\n",
        "\n",
        "* **Output**: Depending on the task, the RNN may produce an output at each time step (sequence-to-sequence) or only at the final time step (sequence-to-vector). The output at each time step 𝑡 is computed based on the current hidden state\n",
        "ℎ\n",
        "𝑡.\n",
        "\n",
        "* **Training**: RNNs are typically trained using backpropagation through time (BPTT), which is an extension of the standard backpropagation algorithm. BPTT computes the gradients of the loss function with respect to the model parameters (weights and biases) by unrolling the network through time and applying the chain rule."
      ],
      "metadata": {
        "id": "swzYDvR4iJfV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# How to convert words into vectors?\n",
        "\n",
        "In Recurrent Neural Networks (RNNs), integer encoding and word embedding are two common techniques used to represent words as vectors before feeding them into the model.\n",
        "\n"
      ],
      "metadata": {
        "id": "nQwyotFjdnEM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RZavg1IVWywU"
      },
      "outputs": [],
      "source": [
        "from keras.datasets import imdb\n",
        "from keras import Sequential\n",
        "from keras.layers import Dense,SimpleRNN"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(train_input,train_target),(test_input,test_target) = imdb.load_data()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u0gtOaf8XJNZ",
        "outputId": "6fa8b2fb-574b-4707-fafb-1ff0549b177d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "17464789/17464789 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_input[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GlZ-fmWzXZGp",
        "outputId": "01b39066-4beb-4de2-ddbd-76a98c4ed4f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1,\n",
              " 14,\n",
              " 22,\n",
              " 16,\n",
              " 43,\n",
              " 530,\n",
              " 973,\n",
              " 1622,\n",
              " 1385,\n",
              " 65,\n",
              " 458,\n",
              " 4468,\n",
              " 66,\n",
              " 3941,\n",
              " 4,\n",
              " 173,\n",
              " 36,\n",
              " 256,\n",
              " 5,\n",
              " 25,\n",
              " 100,\n",
              " 43,\n",
              " 838,\n",
              " 112,\n",
              " 50,\n",
              " 670,\n",
              " 22665,\n",
              " 9,\n",
              " 35,\n",
              " 480,\n",
              " 284,\n",
              " 5,\n",
              " 150,\n",
              " 4,\n",
              " 172,\n",
              " 112,\n",
              " 167,\n",
              " 21631,\n",
              " 336,\n",
              " 385,\n",
              " 39,\n",
              " 4,\n",
              " 172,\n",
              " 4536,\n",
              " 1111,\n",
              " 17,\n",
              " 546,\n",
              " 38,\n",
              " 13,\n",
              " 447,\n",
              " 4,\n",
              " 192,\n",
              " 50,\n",
              " 16,\n",
              " 6,\n",
              " 147,\n",
              " 2025,\n",
              " 19,\n",
              " 14,\n",
              " 22,\n",
              " 4,\n",
              " 1920,\n",
              " 4613,\n",
              " 469,\n",
              " 4,\n",
              " 22,\n",
              " 71,\n",
              " 87,\n",
              " 12,\n",
              " 16,\n",
              " 43,\n",
              " 530,\n",
              " 38,\n",
              " 76,\n",
              " 15,\n",
              " 13,\n",
              " 1247,\n",
              " 4,\n",
              " 22,\n",
              " 17,\n",
              " 515,\n",
              " 17,\n",
              " 12,\n",
              " 16,\n",
              " 626,\n",
              " 18,\n",
              " 19193,\n",
              " 5,\n",
              " 62,\n",
              " 386,\n",
              " 12,\n",
              " 8,\n",
              " 316,\n",
              " 8,\n",
              " 106,\n",
              " 5,\n",
              " 4,\n",
              " 2223,\n",
              " 5244,\n",
              " 16,\n",
              " 480,\n",
              " 66,\n",
              " 3785,\n",
              " 33,\n",
              " 4,\n",
              " 130,\n",
              " 12,\n",
              " 16,\n",
              " 38,\n",
              " 619,\n",
              " 5,\n",
              " 25,\n",
              " 124,\n",
              " 51,\n",
              " 36,\n",
              " 135,\n",
              " 48,\n",
              " 25,\n",
              " 1415,\n",
              " 33,\n",
              " 6,\n",
              " 22,\n",
              " 12,\n",
              " 215,\n",
              " 28,\n",
              " 77,\n",
              " 52,\n",
              " 5,\n",
              " 14,\n",
              " 407,\n",
              " 16,\n",
              " 82,\n",
              " 10311,\n",
              " 8,\n",
              " 4,\n",
              " 107,\n",
              " 117,\n",
              " 5952,\n",
              " 15,\n",
              " 256,\n",
              " 4,\n",
              " 31050,\n",
              " 7,\n",
              " 3766,\n",
              " 5,\n",
              " 723,\n",
              " 36,\n",
              " 71,\n",
              " 43,\n",
              " 530,\n",
              " 476,\n",
              " 26,\n",
              " 400,\n",
              " 317,\n",
              " 46,\n",
              " 7,\n",
              " 4,\n",
              " 12118,\n",
              " 1029,\n",
              " 13,\n",
              " 104,\n",
              " 88,\n",
              " 4,\n",
              " 381,\n",
              " 15,\n",
              " 297,\n",
              " 98,\n",
              " 32,\n",
              " 2071,\n",
              " 56,\n",
              " 26,\n",
              " 141,\n",
              " 6,\n",
              " 194,\n",
              " 7486,\n",
              " 18,\n",
              " 4,\n",
              " 226,\n",
              " 22,\n",
              " 21,\n",
              " 134,\n",
              " 476,\n",
              " 26,\n",
              " 480,\n",
              " 5,\n",
              " 144,\n",
              " 30,\n",
              " 5535,\n",
              " 18,\n",
              " 51,\n",
              " 36,\n",
              " 28,\n",
              " 224,\n",
              " 92,\n",
              " 25,\n",
              " 104,\n",
              " 4,\n",
              " 226,\n",
              " 65,\n",
              " 16,\n",
              " 38,\n",
              " 1334,\n",
              " 88,\n",
              " 12,\n",
              " 16,\n",
              " 283,\n",
              " 5,\n",
              " 16,\n",
              " 4472,\n",
              " 113,\n",
              " 103,\n",
              " 32,\n",
              " 15,\n",
              " 16,\n",
              " 5345,\n",
              " 19,\n",
              " 178,\n",
              " 32]"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_input[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zkrE7hwPXdmD",
        "outputId": "2873cd9c-fa7a-4020-f0f1-b0b80cad9d0a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "218"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.utils import pad_sequences"
      ],
      "metadata": {
        "id": "DbwhaTimXt-R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_input = pad_sequences(train_input,padding='post',maxlen=100)\n",
        "test_input = pad_sequences(test_input,padding='post',maxlen=100)"
      ],
      "metadata": {
        "id": "kFw0Gv_AXhnx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Integer Encoding:\n",
        "\n",
        "Integer encoding involves assigning a unique integer index to each word in the vocabulary.\n",
        "\n",
        "Each word in the input text is replaced by its corresponding integer index.\n",
        "\n",
        "Integer encoding is a simple and efficient way to represent words as numerical values. However, it does not capture the semantic relationships between words.\n",
        "\n",
        "Integer-encoded sequences are typically one-hot encoded before being fed into the RNN."
      ],
      "metadata": {
        "id": "obAYbu1gck_Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(SimpleRNN(32, input_shape=(100,1), return_sequences=False))\n",
        "model.add(Dense(1,activation='sigmoid'))\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yMzs8BwXX4Ns",
        "outputId": "a2900295-cadb-4884-e3c0-06b39dae526e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " simple_rnn (SimpleRNN)      (None, 32)                1088      \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 33        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1121 (4.38 KB)\n",
            "Trainable params: 1121 (4.38 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "\n",
        "model.fit(train_input,train_target,epochs=5,validation_data=(test_input,test_target))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UQ0KdXDnYHrB",
        "outputId": "82e2d85f-287e-4dc9-8091-421a51b4d1b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "782/782 [==============================] - 52s 64ms/step - loss: 0.6946 - accuracy: 0.5040 - val_loss: 0.6925 - val_accuracy: 0.5109\n",
            "Epoch 2/5\n",
            "782/782 [==============================] - 48s 61ms/step - loss: 0.6933 - accuracy: 0.5101 - val_loss: 0.6924 - val_accuracy: 0.5137\n",
            "Epoch 3/5\n",
            "782/782 [==============================] - 48s 62ms/step - loss: 0.6930 - accuracy: 0.5113 - val_loss: 0.6943 - val_accuracy: 0.5051\n",
            "Epoch 4/5\n",
            "782/782 [==============================] - 48s 61ms/step - loss: 0.6928 - accuracy: 0.5116 - val_loss: 0.6946 - val_accuracy: 0.5109\n",
            "Epoch 5/5\n",
            "782/782 [==============================] - 48s 62ms/step - loss: 0.6927 - accuracy: 0.5111 - val_loss: 0.6939 - val_accuracy: 0.4997\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7f0bcd35dd50>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## Word Embedding:\n",
        "\n",
        "Word embedding is a dense vector representation of words in a high-dimensional space, during the training process to capture semantic relationships between words. It is capable of capturing context and meaning from the surrounding words in a sequence.\n",
        "\n",
        "**Note:** Words with similar meanings are represented by similar vectors in the embedding space.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Mn3kVZzVb-Nc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import Embedding"
      ],
      "metadata": {
        "id": "V_gPfLOAZejV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "`embeddings_initializer='uniform'` is an argument passed to the Embedding layer in the Keras model. It specifies the method used to initialize the embedding weights, which are the vectors that represent each word in the vocabulary.\n",
        "\n",
        "The 'uniform' initializer randomly initializes the weights within a uniform distribution. This means that each weight is sampled from a uniform distribution between a lower and upper bound. The default lower and upper bounds are -1 and 1, respectively.\n",
        "\n",
        "-- It is often used when there is no prior knowledge about the relationships between the words in the vocabulary."
      ],
      "metadata": {
        "id": "U90uxh2Xbsn9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_1 = Sequential()\n",
        "\n",
        "model_1.add(Embedding(10000, 2, input_length=100, embeddings_initializer='uniform'))\n",
        "model_1.add(SimpleRNN(32,return_sequences=False))\n",
        "model_1.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model_1.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BNdzHYJFZefq",
        "outputId": "618f4fe0-094c-4d23-8391-0d778b1e63af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_1 (Embedding)     (None, 100, 2)            20000     \n",
            "                                                                 \n",
            " simple_rnn_1 (SimpleRNN)    (None, 32)                1120      \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 33        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 21153 (82.63 KB)\n",
            "Trainable params: 21153 (82.63 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_1.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
        "history = model_1.fit(train_input,train_target,epochs=5,validation_data=(test_input,test_target))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IVUKV_q2Zec3",
        "outputId": "b92fe152-c414-4510-aafa-fc6ef0be11c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "782/782 [==============================] - 101s 125ms/step - loss: 0.6826 - acc: 0.5648 - val_loss: 0.6364 - val_acc: 0.6627\n",
            "Epoch 2/5\n",
            "782/782 [==============================] - 72s 93ms/step - loss: 0.5210 - acc: 0.7473 - val_loss: 0.4240 - val_acc: 0.8092\n",
            "Epoch 3/5\n",
            "782/782 [==============================] - 75s 96ms/step - loss: 0.3712 - acc: 0.8450 - val_loss: 0.4197 - val_acc: 0.8237\n",
            "Epoch 4/5\n",
            "782/782 [==============================] - 79s 102ms/step - loss: 0.2892 - acc: 0.8853 - val_loss: 0.4265 - val_acc: 0.8312\n",
            "Epoch 5/5\n",
            "782/782 [==============================] - 76s 97ms/step - loss: 0.2481 - acc: 0.9067 - val_loss: 0.4215 - val_acc: 0.8344\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Little overfitting but better accuracy than Interger Encoding Vectors.\n",
        "\n",
        "Word embeddings are more expressive than integer encoding and are widely used in natural language processing, NLP tasks."
      ],
      "metadata": {
        "id": "P5K21IZshu2B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Applications of RNN\n",
        "\n",
        "RNNs are well-suited for tasks involving sequential data, such as natural language processing (e.g., language modeling, machine translation, sentiment analysis), time series analysis (e.g., stock price prediction, weather forecasting), and speech recognition.\n",
        "\n",
        "## What are the limitations of recurrent neural networks?\n",
        "\n",
        "* **Exploding gradient**\n",
        "\n",
        "Gradient exploding refers to the phenomenon where gradients become extremely large during the backpropagation process, causing the weights of the network to update by large amounts.\n",
        "\n",
        "In RNNs, gradient exploding often occurs when the gradients are backpropagated through many time steps, causing them to accumulate and grow exponentially.\n",
        "\n",
        "This can lead to unstable training behavior and make it difficult for the model to converge to a good solution.\n",
        "\n",
        "* **Vanishing gradient**\n",
        "\n",
        "The vanishing gradient problem is a condition where the model’s gradient approaches zero in training. When the gradient vanishes, the RNN fails to learn effectively from the training data, resulting in underfitting.\n",
        "\n",
        "An underfit model can’t perform well in real-life applications because its weights weren’t adjusted appropriately. RNNs are at risk of vanishing and exploding gradient issues when they process long data sequences.\n",
        "\n",
        "* **Slow training time**\n",
        "\n",
        "In RNNs, slow training can be caused by various factors, including gradient exploding or vanishing gradients, which can make it difficult for the model to learn effectively from the training data.\n",
        "\n",
        "Additionally, the computational complexity of training RNNs, especially when processing long sequences or large datasets, can contribute to slow training times.\n",
        "\n",
        " For example, an RNN model can analyze a user’s sentiment from a couple of sentences. However, it requires massive computing power, memory space, and time to summarize a page of an essay.\n",
        "\n",
        "\n",
        "## What are some variants of recurrent neural network architecture?\n",
        "\n",
        "1. **Bidirectional Recurrent Neural Networks (BRNN)**\n",
        "\n",
        "This architecture processes data sequences with forward and backward layers of hidden nodes.\n",
        "\n",
        "The forward layer works similarly to the RNN, which stores the previous input in the hidden state and uses it to predict the subsequent output.\n",
        "\n",
        " Meanwhile, the backward layer works in the opposite direction by taking both the current input and the future hidden state to update the present hidden state.\n",
        "\n",
        "  Combining both layers enables the BRNN to improve prediction accuracy by considering past and future contexts.\n",
        "\n",
        "**Advantage**: Improves prediction accuracy by considering past and future contexts.\n",
        "\n",
        "**Example**: Predicting the word \"enjoy\" in the sentence \"You enjoy data science.\"\n",
        "\n",
        "2. **Long Short-Term Memory (LSTM) Networks**\n",
        "\n",
        "This RNN variant enables the model to expand its memory capacity to accommodate a longer timeline.\n",
        "\n",
        "Whereas, RNN can only remember the immediate past input. It can’t use inputs from several previous sequences to improve its prediction.\n",
        "\n",
        "**Advantage**: Enables the model to remember dependencies over longer sequences.\n",
        "\n",
        "**Example**: \"You love data science. Your favorite topic is RNN.\", the LSTM might recognize the relationship between \"data science\" and \"RNN\" as related topics.\n",
        "\n",
        "3. **Gated Recurrent Units (GRU)**\n",
        "\n",
        "It is an RNN that enables selective memory retention. The model adds an update and forgets the gate to its hidden layer, which can store or remove information in the memory.\n",
        "\n",
        "**Advantage**: Provides a balance between memory retention and computational efficiency. Selectively remembering important information while discarding irrelevant details.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "## How do transformers overcome the limitations of recurrent neural networks?\n",
        "\n",
        "Transformers are deep learning models that use self-attention mechanisms in an encoder-decoder feed-forward neural network. They can process sequential data the same way that RNNs do.\n",
        "\n",
        "* **Self-attention**\n",
        "\n",
        "Transformers don’t use hidden states to capture the interdependencies of data sequences. Instead, they use a self-attention head to process data sequences in parallel.\n",
        "\n",
        "This enables transformers to train and process longer sequences in less time than an RNN does. With the self-attention mechanism, transformers overcome the memory limitations and sequence interdependencies that RNNs face.\n",
        "\n",
        "Transformers can process data sequences in parallel and use positional encoding to remember how each input relates to others.\n",
        "\n",
        "* **Parallelism**\n",
        "\n",
        "Transformers solve the gradient issues that RNNs face by enabling parallelism during training. By processing all input sequences simultaneously, a transformer isn’t subjected to backpropagation restrictions because gradients can flow freely to all weights.\n",
        "\n",
        "They are also optimized for parallel computing, which graphic processing units (GPUs) offer for generative AI developments. Parallelism enables transformers to scale massively and handle complex NLP tasks by building larger models."
      ],
      "metadata": {
        "id": "0oJXZKPwg01Z"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zg-XaXphtja1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}